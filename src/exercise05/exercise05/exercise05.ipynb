{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 05: Gaussian Process Model Predictive Control (GP-MPC)\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Model mismatch is a frequent source of control inaccuracy in real-world applications of MPC. Since MPC is a optimization-based control method, MPCs will try to exploit the given model dynamics as much as possible, which may cause it to become instable with the real dynamics.\n",
    "\n",
    "One research direction is to find a good approximation of the difference $d(x,u)$ between the nominal model $f_{\\text{nominal}}(x,u)$ and the real model, i.e.,\n",
    "\n",
    "$$ \\dot{x} = f_{\\text{nominal}}(x,u) + d(x,u),$$\n",
    "\n",
    "This approximation can be achieved via learning-based methods, and Gaussian Processes (GPs) are one such method. \n",
    "\n",
    "GPs have the inherent advantage that they also provide uncertainty estimates which can be used to ensure stochastic constraint satisfaction and to improve the robustness of the MPC controller.\n",
    "\n",
    "In this exercise, we focus on GP-MPC which models the residual dynamics with GPs and uses the uncertainty estimates to tighten the future state and input constraints.\n",
    "\n",
    "We then compare the performance between GP-MPC and nominal MPC when tracking a trajectory with a simulated drone under model mismatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because it can cause issues when changing the gpmpc parameters\n",
    "# As a workaround we (re-)import the required modules at the beginning of each cell\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import crazyflow  # noqa: F401, required for registering environments\n",
    "import gymnasium\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from exercise05.run_gpmpc import Evaluator\n",
    "from exercise05.utils import remove_path, set_seed\n",
    "from gymnasium.wrappers.vector.jax_to_numpy import JaxToNumpy\n",
    "\n",
    "# select global seed and device\n",
    "global_seed = 0\n",
    "set_seed(global_seed)\n",
    "if not torch.cuda.is_available():\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    device = \"cuda\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Environment and the Trajectory to Follow\n",
    "First, we create an environment with a figure-eight trajectory in the x–y plane as the reference trajectory, extract the trajectory, and the action space limits. Then we distort the (identified) drone dynamics to simulate model mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = JaxToNumpy(gymnasium.make_vec(\"DroneFigureEightTrajectory-v0\", num_envs=1))\n",
    "traj = env.unwrapped.trajectory.T\n",
    "# Pad the trajectory with zeros to match the state dimension (12)\n",
    "traj = np.concatenate([traj, np.zeros((9, traj.shape[1]))], axis=0)\n",
    "env.unwrapped.render_trajectory = False\n",
    "\n",
    "# Correct params of the dynamics model\n",
    "correct_params = {\n",
    "        \"a\": 20.9,\n",
    "        \"b\": 3.6,\n",
    "        \"ra\": -130,\n",
    "        \"rb\": -16.3,\n",
    "        \"rc\": 119.3,\n",
    "        \"pa\": -100.0,\n",
    "        \"pb\": -13.3,\n",
    "        \"pc\": 84.47,\n",
    "        \"ya\": -0.01,\n",
    "        \"yb\": 0.0,\n",
    "        \"yc\": 0.0,\n",
    "    }\n",
    "\n",
    "def disturb_params(params, scale=0.1):\n",
    "    params = params.copy()\n",
    "    for k, v in params.items():\n",
    "        params[k] = v * (1 + scale * (2 * np.random.rand() - 1))\n",
    "    return params\n",
    "\n",
    "# Plot the trajectory\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(traj[0, :], traj[2, :])\n",
    "plt.xlabel(\"x [m]\")\n",
    "plt.ylabel(\"y [m]\")\n",
    "plt.title(\"Trajectory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement the GP‑MPC Controller\n",
    "\n",
    "We augment the nominal dynamics with a learned residual model\n",
    "$$\n",
    "x_{k+1}=f_{\\text{nom}}(x_k,u_k)+d(x_k,u_k),\n",
    "$$\n",
    "where the residual $d(\\cdot)$ is represented by a small set of sparse variational Gaussian Processes (SVGPs). We then (i) construct an efficiently evaluable residual parameterization, (ii) embed it into the discrete MPC dynamics, and (iii) tighten constraints using the GP predictive variance to achieve probabilistic satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Parameterize the Residual Dynamics with Sparse Variational GPs\n",
    "\n",
    "**Why sparse & low–dimensional?** MPC requires hundreds–thousands of repeated dynamics + Jacobian evaluations per second. A naïve GP with $N$ data points costs $\\mathcal{O}(N^3)$ to train and $\\mathcal{O}(N)$ per query. We therefore:\n",
    "1. Use an SVGP (variational inducing point approximation) with $M\\ll N$.\n",
    "2. Decompose the residual into a *small* set of independent scalar GPs over carefully chosen, low‑dimensional input groups (feature grouping).\n",
    "3. Export only the minimal quantities required inside the solver (inducing inputs + a compressed weight vector $\\alpha$).\n",
    "\n",
    "**Grouping used (attitude + thrust residual):**\n",
    "- GP 1: thrust command  → thrust residual (mapped to body accelerations).\n",
    "- GP 2: (φ, dφ, φ_cmd)   → roll‑rate residual.\n",
    "- GP 3: (θ, dθ, θ_cmd)   → pitch‑rate residual.\n",
    "\n",
    "Each scalar GP provides a predictive mean; we ignore cross‑covariances for speed (diagonal residual covariance).\n",
    "\n",
    "**Sparse parameterization inserted into CasADi:**\n",
    "For an input $z\\in\\mathbb{R}^{d}$ and inducing set $Z\\in\\mathbb{R}^{M\\times d}$,\n",
    "$$\n",
    "\\mu(z)\\approx k(z,Z)\\,K_{ZZ}^{-1} m_u \\;\\; \\Longrightarrow \\;\\; \\mu(z)=k(z,Z)\\,\\alpha,\n",
    "$$\n",
    "where we precompute $\\alpha=K_{ZZ}^{-1} m_u$. We pass the flattened vector\n",
    "$$\n",
    "\\theta = [\\alpha,\\; Z]\n",
    "$$\n",
    "as an MPC parameter. Each GP contributes its own $\\theta_i$; all are concatenated.\n",
    "\n",
    "**Resulting residual vector build:**\n",
    "- Convert thrust residual to (a_x,a_y,a_z) with current attitude.\n",
    "- Insert angular rate residuals in the appropriate state derivative components.\n",
    "- Unspecified components remain zero.\n",
    "\n",
    "**Numerical stability:** GPs can be very sensitive to numerical issues. This can be counteracted by: Appropriate hyperparameter initialization, enforcing lower bounds on lengthscales, using a numerically robust Cholesky decomposition, and selecting the inducing points well.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <h3>Task 1: Parameterize the Residual Dynamics</h3>\n",
    "  <p> Task 1.1: Review the nominal model: <code>symbolic_attitude</code> and <code>SymbolicModel</code> (Crazyflow package). </p>\n",
    "  <p> Task 1.2: Inspect <code>exercise05/gp.py</code>, then complete following methods of the <code>_SingleOutputSVGP</code> class: </p>\n",
    "    <ul>\n",
    "        <li><code>get_sparse_parameterization</code>: create a casadi expression of &mu;(z) as a function of &alpha; and the inducing points.</li>\n",
    "        <li><code>get_sparse_parameters</code>: extract &alpha; and the inducing points from the trained GP model.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Embedding the Residual GP in the MPC Dynamics\n",
    "\n",
    "We create a modified Acados model:\n",
    "$x_{k+1}= \\Phi_{\\Delta t}\\big(f_{\\text{nom}}(x_k,u_k)+d(x_k,u_k)\\big),$\n",
    "implemented by replacing the discrete dynamics expression with RK4 over the *augmented* continuous field.\n",
    "\n",
    "Steps performed in `GPMPC` (see `exercise05/gpmpc.py`):\n",
    "1. Collect state & input symbols; build grouped GP inputs (`gp_inputs` list).\n",
    "2. Obtain symbolic residual expressions + parameter symbols from each GP (`get_sparse_parameterization`).\n",
    "3. Assemble the residual dynamics vector from the individual GP means.\n",
    "4. Register a single concatenated parameter vector (`gp_params`) with the OCP registry (enables fast in‑place updates after re‑training).\n",
    "5. Replace `disc_dyn_expr` with RK4 discretization of nominal + residual dynamics.\n",
    "\n",
    "After (re)training:\n",
    "- Call `self.gpmpc_registry.update_params(..., which=[\"gp_params\"])` to push the updated parameters into the solver without regeneration of code.\n",
    "<div class=\"alert alert-info\">\n",
    "  <h3>Task 2: Augment MPC with Residual Dynamics</h3>\n",
    "  <p> Task 2.1 Review and understand the <code>_add_residual_dynamics_to_acados_model</code> method in <code>exercise05/gpmpc.py</code> </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Probabilistic Constraint Tightening via GP Uncertainty\n",
    "\n",
    "We want\n",
    "$$\n",
    "\\Pr( A_x x_k \\le b_x ) \\ge p,\\qquad \\Pr( A_u u_k \\le b_u ) \\ge p\n",
    "$$\n",
    "under additive residual uncertainty. We linearize around the current planned trajectory and propagate a Gaussian covariance.\n",
    "\n",
    "Linearized deviation dynamics (nominal + residual mean):\n",
    "$$\n",
    "\\delta x_{k+1}=A_k \\delta x_k + B_k \\delta u_k + B_{d,k} w_k,\\quad w_k\\sim\\mathcal{N}(0,\\Sigma_{d,k})\n",
    "$$\n",
    "with:\n",
    "- $A_k=\\frac{\\partial f_{\\text{nom}}}{\\partial x}$,\n",
    "- $B_k=\\frac{\\partial f_{\\text{nom}}}{\\partial u}$,\n",
    "- $B_{d,k}$ maps residual components to the affected state derivatives (sparse),\n",
    "- $\\Sigma_{d,k}=\\operatorname{diag}(\\sigma^2_{\\text{GP},k})$ (diagonal, per GP output).\n",
    "\n",
    "Covariance recursion:\n",
    "$$\n",
    "\\Sigma_{x,k+1}=A_k \\Sigma_{x,k} A_k^\\top + B_k \\Sigma_{u,k} B_k^\\top + B_{d,k} \\Sigma_{d,k} B_{d,k}^\\top\n",
    "+ A_k \\Sigma_{x,u,k} B_k^\\top + B_k \\Sigma_{x,u,k}^\\top A_k^\\top\n",
    "$$\n",
    "In our simplified implementation we:\n",
    "1. Start with $\\Sigma_{x,0}=0$.\n",
    "2. Obtain GP predictive variances along the *current* nominal trajectory (treating controls fixed).\n",
    "3. Propagate forward with a precomputed stabilizing LQR gain $K$ used to approximate the closed‑loop input fluctuation: $\\delta u_k \\approx K \\delta x_k$.\n",
    "4. Extract per‑component standard deviations.\n",
    "\n",
    "Constraint tightening (Bonferroni / union bound style):\n",
    "For each scalar inequality $a_i^\\top x \\le b_i$, replace with\n",
    "$$\n",
    "a_i^\\top x \\le b_i - \\Phi^{-1}(p_i)\\,\\sqrt{a_i^\\top \\Sigma_x a_i},\n",
    "$$\n",
    "where $p_i$ is chosen so overall probability ≥ desired `prob`. Code precomputes a conservative quantile (see `inverse_cdf` in `GPMPC.__init__`).\n",
    "\n",
    "Margins for inputs (analogous) use $\\Sigma_u = K\\Sigma_x K^\\top$.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <h3>Task 3: Implement the Constraint Tightening</h3>\n",
    "  <p> Task 3.1: Complete the <code>create_tightened_constraints</code> method in <code>exercise05/gpmpc.py</code>. </p>\n",
    "    <p> Task 3.2: Complete the <code>setup_prior_dynamics</code> function in <code>exercise05/mpc.py</code> .</p>\n",
    "    <p> Task 3.3 (Optional) Review and complete <code>update_tightening_parameters</code> in <code>exercise05/gpmpc.py</code> and ensure the covariance propagation and margin computation matches the above explanations. This is a bonus task and not required to complete the exercise. When not completing the function, set prob to 0.0 in the config to disable tightening.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Training Loop & Evaluation\n",
    "\n",
    "We iteratively:\n",
    "1. Roll out current (GP-)MPC → collect (x,u,x') data.\n",
    "2. Add residual samples to replay buffer (`add_data`).\n",
    "3. (Re)fit SVGPs (`fit`), update parameters in solver.\n",
    "4. Re-run evaluation episodes and log tracking MSE.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <h3>Task 4: Run and Evaluate the GP-MPC</h3>\n",
    "  <p> Task 4.1: Run and compare nominal MPC (epoch 0) vs successive GP-MPC epochs (plots + MSE). </p>\n",
    "  <p> Task 4.2: Tune hyperparameters: inducing points, horizon, cost weights, constraint probability level. </p>\n",
    "  <p> Task 4.3: Discuss: diminishing returns, effect of probability level, effect of inducing point count. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exercise05.gpmpc import GPMPC  # noqa: F401, reimport for edits\n",
    "from exercise05.mpc import MPC  # noqa: F401, reimport for edits\n",
    "\n",
    "ctrl = None\n",
    "output_dir = Path(Path.cwd() / \"ctrl_outputs\")\n",
    "remove_path(output_dir)  # Clean up previous code to prevent interference\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set distortion scale\n",
    "prior_params = disturb_params(correct_params, scale=1.0)\n",
    "prior_params[\"a\"] = 5.0  # Make it really bad\n",
    "\n",
    "# Parameters to play with\n",
    "cfg = {\n",
    "    \"prob\": 0.0, # Only change if you implemented the constraint tightening\n",
    "    \"replay_buffer\": {\"max_size\": 2000, \"data_selection\": \"rnd\"},\n",
    "    \"mpc\": {\n",
    "        \"horizon\": 70,\n",
    "        \"cost_params\": {\"Q\": [100, 0.1, 100, 0.5, 0.5, 0.5, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01], \"R\": [4, 0.5, 0.5, 0.5]},\n",
    "    },\n",
    "    \"gp\": {\"n_inducing_points\": 20},\n",
    "    \"gp_train\": {\"lr\": 1e-3, \"epochs\": 200, \"patience\": 20},\n",
    "}\n",
    "\n",
    "ctrl = GPMPC(env=env.unwrapped, prior_params=prior_params, cfg=cfg, output_dir=output_dir, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: If the optimization fails, adjust the parameters and reroll the distortion (or set manually). You can ignore \"adding jitter\" warnings. Also, the GP-MPC training and evaluation can take a while, especially when using the CPU. Adjust the number of epochs, the replay buffer size, the number of inducing points, and the number of evaluation epochs to speed this up if necessary.\n",
    "evaluator = None\n",
    "eval_env = gymnasium.make_vec(\"DroneFigureEightTrajectory-v0\", num_envs=1)\n",
    "evaluator = Evaluator(eval_env, ctrl, seed=global_seed, verbosity=\"info\")\n",
    "evaluator.run(n_epochs=3, extra_train_runs=True)\n",
    "evaluator.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dynamic quality of the learned model\n",
    "run = evaluator.runs[list(evaluator.runs.keys())[-1]]\n",
    "ctrl.evaluate_dynamics_quality(test_x=run[\"obs\"][:-1, :], test_u=run[\"action\"], test_x_next=run[\"obs\"][1:, :], plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: Performance of MPC and GP-MPC Controllers\n",
    "\n",
    "#### Reasons for Weak Performance of MPC-based Controllers\n",
    "\n",
    "- **Control Constraints & Cost Function Tuning:**  \n",
    "  The MPC’s tracking performance is fundamentally limited by actuator constraints (e.g., thrust, rate limits) and the weights in the cost function. If the cost function is not carefully tuned to prioritize tracking the most important states (such as x and y positions), or if input penalties are too high, the controller may avoid aggressive maneuvers and tolerate tracking errors. Hard constraints can also prevent the controller from following aggressive or sharp trajectory segments.\n",
    "\n",
    "- **Reference Trajectory Feasibility:**  \n",
    "  The reference trajectory itself may be physically infeasible or require actions that exceed the system’s capabilities. Even with a perfect model, the controller cannot track a trajectory that is not dynamically feasible given the system’s physical and actuation limits.\n",
    "\n",
    "- **Model Structure, Underactuation, and Real-World Effects:**  \n",
    "  Even with a perfect model, real-world factors such as unmodeled dynamics, sensor noise, disturbances, and discretization errors can degrade tracking. Underactuated systems (where not all degrees of freedom are directly controlled) further limit tracking performance.\n",
    "\n",
    "- **Prediction Horizon Limitations:**  \n",
    "  The finite prediction horizon of MPC means the controller can only optimize over a limited future window. A short horizon can limit the ability to anticipate and plan for future trajectory changes, especially for aggressive or rapidly changing references.\n",
    "\n",
    "#### Reasons for Limited Improvement with GP-MPC or Even Worse Performance\n",
    "\n",
    "- **Marginal Gains After Initial Learning:**  \n",
    "  GP-MPC often shows some improvement over nominal MPC after initial training, as the GP learns to correct systematic model errors. However, further improvements typically plateau. The GP can only correct for model errors it has seen in the training data, and its generalization is limited by the diversity and representativeness of that data.\n",
    "\n",
    "- **Data Efficiency & Generalization:**  \n",
    "  GPs require sufficient and representative data to accurately model the residual dynamics. If the training data does not cover the full range of operating conditions, or is too limited, the GP’s corrections will be incomplete or inaccurate.\n",
    "\n",
    "- **Model Structure & Expressiveness:**  \n",
    "  The GP’s input selection, kernel choice, and output structure may not be expressive enough to capture all relevant model errors. Over-regularization or poor hyperparameter choices can lead to underfitting.\n",
    "\n",
    "- **Uncertainty Propagation & Constraint Tightening:**  \n",
    "  GP-MPC propagates uncertainty through the dynamics and tightens constraints to ensure probabilistic safety. If the GP’s uncertainty estimates are inaccurate, or if the constraint tightening is too conservative, the controller may become overly cautious, reducing its ability to exploit the learned model and track the reference closely.\n",
    "\n",
    "- **Computational and Practical Limitations:**  \n",
    "  Sparse GP approximations (e.g., FITC) are used for tractability, but can reduce GP accuracy, especially for highly nonlinear or high-dimensional systems. Limited computational resources may restrict the number of inducing points or training iterations.\n",
    "\n",
    "#### Key Takeaways\n",
    "\n",
    "- **MPC performance is fundamentally limited by system constraints, cost function design, and model accuracy.** Even with a perfect model, perfect tracking is generally not possible due to these limitations.\n",
    "- **GP-MPC can improve performance by learning and compensating for model errors,** but its effectiveness is limited by the quality and quantity of training data, the expressiveness of the GP model, and the conservatism introduced by uncertainty propagation.\n",
    "- **Perfect tracking is rarely achievable in practice.** Both MPC and GP-MPC are subject to fundamental trade-offs between safety, robustness, performance, and computational complexity.\n",
    "- **Further improvements may require richer data, better model structures, or hybrid learning/model-based approaches.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "\n",
    "[1] Hewing, L., Kabzan, J., & Zeilinger, M. N. (2020). Cautious Model Predictive Control Using Gaussian Process Regression. IEEE Transactions on Control Systems Technology, 28(6), 2736–2743.\n",
    "\n",
    "[2] Wang, J., & Zhang, Y. (2024). A Tutorial on Gaussian Process Learning-based Model Predictive Control. arXiv preprint arXiv:2404.03689.\n",
    "\n",
    "[3] A. Mesbah et al., \"Fusion of Machine Learning and MPC under Uncertainty: What Advances Are on the Horizon?,\" 2022 American Control Conference (ACC), Atlanta, GA, USA, 2022, pp. 342-357."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
